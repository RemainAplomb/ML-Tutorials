{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "1gIclttuUB_H",
        "Y-H7tlHN3yo9",
        "J3QHVXIl3_fM",
        "1gP_XhctZOJD",
        "-g0YySRx31rD",
        "Q7S6ny9K4eU7",
        "mPxo45LxjGbA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Change python interpreter (Working)"
      ],
      "metadata": {
        "id": "1gIclttuUB_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install python 3.9 and dev utils\n",
        "#you may not need all the dev libraries, but I haven't tested which aren't necessary.\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.7 python3.7-dev python3.7-distutils libpython3.7-dev\n",
        "\n",
        "#change alternatives\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.7 2\n",
        "\n",
        "# install pip\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3 get-pip.py --force-reinstall\n",
        "\n",
        "#install colab's dependencies\n",
        "!python3 -m pip install ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "# link to the old google package\n",
        "!ln -s /usr/local/lib/python3.8/dist-packages/google \\\n",
        "       /usr/local/lib/python3.7/dist-packages/google"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3VwcOEOXgLx",
        "outputId": "1773fd85-069e-4e27-cafb-e0d7536a422d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 264 kB in 2s (146 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Note, selecting 'python3-distutils' instead of 'python3.7-distutils'\n",
            "python3-distutils is already the newest version (3.6.9-1~18.04).\n",
            "python3-distutils set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libpython3.7 libpython3.7-minimal libpython3.7-stdlib python3.7-minimal\n",
            "Suggested packages:\n",
            "  python3.7-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.7 libpython3.7-dev libpython3.7-minimal libpython3.7-stdlib\n",
            "  python3.7 python3.7-dev python3.7-minimal\n",
            "0 upgraded, 7 newly installed, 0 to remove and 20 not upgraded.\n",
            "Need to get 49.3 MB of archives.\n",
            "After this operation, 89.7 MB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-minimal amd64 3.7.16-1+bionic1 [589 kB]\n",
            "Get:2 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-minimal amd64 3.7.16-1+bionic1 [1,725 kB]\n",
            "Get:3 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-stdlib amd64 3.7.16-1+bionic1 [1,773 kB]\n",
            "Get:4 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7 amd64 3.7.16-1+bionic1 [1,527 kB]\n",
            "Get:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 libpython3.7-dev amd64 3.7.16-1+bionic1 [42.9 MB]\n",
            "Get:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7 amd64 3.7.16-1+bionic1 [360 kB]\n",
            "Get:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 python3.7-dev amd64 3.7.16-1+bionic1 [501 kB]\n",
            "Fetched 49.3 MB in 16s (3,059 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 7.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
            "(Reading database ... 124016 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package python3.7-minimal.\n",
            "Preparing to unpack .../1-python3.7-minimal_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.7-minimal (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.7-stdlib_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.7:amd64.\n",
            "Preparing to unpack .../3-libpython3.7_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package libpython3.7-dev:amd64.\n",
            "Preparing to unpack .../4-libpython3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package python3.7.\n",
            "Preparing to unpack .../5-python3.7_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.7 (3.7.16-1+bionic1) ...\n",
            "Selecting previously unselected package python3.7-dev.\n",
            "Preparing to unpack .../6-python3.7-dev_3.7.16-1+bionic1_amd64.deb ...\n",
            "Unpacking python3.7-dev (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7-minimal:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up python3.7-minimal (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7-stdlib:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up python3.7 (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up libpython3.7-dev:amd64 (3.7.16-1+bionic1) ...\n",
            "Setting up python3.7-dev (3.7.16-1+bionic1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "update-alternatives: using /usr/bin/python3.7 to provide /usr/bin/python3 (python3) in auto mode\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2509k  100 2509k    0     0  55.6M      0 --:--:-- --:--:-- --:--:-- 55.6M\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Downloading pip-22.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-65.6.3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.38.4-py3-none-any.whl (36 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-22.3.1 setuptools-65.6.3 wheel-0.38.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython\n",
            "  Downloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython_genutils\n",
            "  Downloading ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.16.2-py3-none-any.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_console\n",
            "  Downloading jupyter_console-6.4.4-py3-none-any.whl (22 kB)\n",
            "Collecting prompt_toolkit\n",
            "  Downloading prompt_toolkit-3.0.36-py3-none-any.whl (386 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.4/386.4 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httplib2\n",
            "  Downloading httplib2-0.21.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.8/96.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astor\n",
            "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython) (65.6.3)\n",
            "Collecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pygments\n",
            "  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting traitlets>=4.2\n",
            "  Downloading traitlets-5.7.1-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.9/109.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting pyzmq>=17\n",
            "  Downloading pyzmq-24.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting debugpy>=1.0\n",
            "  Downloading debugpy-1.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-client>=6.1.12\n",
            "  Downloading jupyter_client-7.4.8-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-22.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Collecting tornado>=6.1\n",
            "  Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.0/424.0 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wcwidth\n",
            "  Downloading wcwidth-0.2.5-py2.py3-none-any.whl (30 kB)\n",
            "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting entrypoints\n",
            "  Downloading entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter-core>=4.9.2\n",
            "  Downloading jupyter_core-4.12.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting six>=1.5\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: wcwidth, ptyprocess, pickleshare, ipython_genutils, backcall, traitlets, tornado, six, pyzmq, pyparsing, pygments, psutil, prompt_toolkit, pexpect, parso, packaging, nest-asyncio, entrypoints, decorator, debugpy, astor, python-dateutil, matplotlib-inline, jupyter-core, jedi, httplib2, jupyter-client, ipython, ipykernel, jupyter_console\n",
            "Successfully installed astor-0.8.1 backcall-0.2.0 debugpy-1.6.4 decorator-5.1.1 entrypoints-0.4 httplib2-0.21.0 ipykernel-6.16.2 ipython-7.34.0 ipython_genutils-0.2.0 jedi-0.18.2 jupyter-client-7.4.8 jupyter-core-4.12.0 jupyter_console-6.4.4 matplotlib-inline-0.1.6 nest-asyncio-1.5.6 packaging-22.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 prompt_toolkit-3.0.36 psutil-5.9.4 ptyprocess-0.7.0 pygments-2.13.0 pyparsing-3.0.9 python-dateutil-2.8.2 pyzmq-24.0.1 six-1.16.0 tornado-6.2 traitlets-5.7.1 wcwidth-0.2.5\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check python version\n",
        "import sys\n",
        "print(sys.version)\n",
        "!python3 --version\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz59sUGqX5WZ",
        "outputId": "28b12d15-9820-49c7-ae0b-1e10c76c2725"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.8.16 (default, Dec  7 2022, 01:12:13) \n",
            "[GCC 7.5.0]\n",
            "Python 3.7.16\n",
            "Python 3.7.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "#Python 3.7.15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOQ5b5zTUQeg",
        "outputId": "347595f2-1b72-4113-c93d-73cb06a8a2bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNa4EFEvUt3u",
        "outputId": "3cb506cc-afed-49e5-ea00-66aa4e542f04"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 22.3.1 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade ipython\n",
        "!pip install -q --upgrade ipykernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7VY0oQnUFzH",
        "outputId": "9087845a-46c3-41b5-f940-c27b508a7adb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Restart runtime after  this\n"
      ],
      "metadata": {
        "id": "TequiLnBg01H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Roboflow Gender Detection"
      ],
      "metadata": {
        "id": "pzKMSM8i3ge2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "Y-H7tlHN3yo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall keras-nightly\n",
        "!pip uninstall -y tensorflow\n",
        "\n",
        "!pip install keras==2.1.6\n",
        "!pip install h5py==2.10.0\n",
        "!pip install tf-slim==1.0\n",
        "!pip install tensorflow==1.15"
      ],
      "metadata": {
        "id": "Tel-vOly3qbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip uninstall -y pycocotools\n",
        "!pip install pycocotools --no-binary pycocotools"
      ],
      "metadata": {
        "id": "QVE49VgKAUqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lvis\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install numpy==1.19.5"
      ],
      "metadata": {
        "id": "kjtHxUCMLypD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "6oafw74XL4n6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart runtime after this"
      ],
      "metadata": {
        "id": "OpqlMwbwg45w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Paths"
      ],
      "metadata": {
        "id": "J3QHVXIl3_fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRuKByiv6_Z7",
        "outputId": "420b81bc-42db-4529-b6ed-8f96958331b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTHONPATH=/env/python/:/content/models/research/:/content/models/research/slim:/content/models/research/deeplab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb5RL75H85gk",
        "outputId": "3fac15dd-1158-4245-f473-1abd0354ed20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTHONPATH=/env/python/:/content/models/research/:/content/models/research/slim:/content/models/research/deeplab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os\n",
        "#os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "metadata": {
        "id": "zPhdzBTa4B10"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKDyFhpz6eok",
        "outputId": "00720553-b27e-427e-bf7b-c61598fda496"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 22.3.1 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## For deletion (Don't run if not needed)"
      ],
      "metadata": {
        "id": "1gP_XhctZOJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete folder\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree('/content/models')\n",
        "\n",
        "shutil.rmtree('/content/tensorflow-object-detection-faster-rcnn')"
      ],
      "metadata": {
        "id": "Rt1No126ZSYB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone repository"
      ],
      "metadata": {
        "id": "-g0YySRx31rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9IMVeFbUIxZ",
        "outputId": "0388ff33-5f36-46a1-823e-7862632395b6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n",
            "Python 3.7.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "id": "gdLKOnN73n3M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "Q7S6ny9K4eU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLoNNzlM9kSl",
        "outputId": "ce2662f3-402b-4b51-f6e8-2e7b69e7aa47"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "70Pk-LsU351B"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6MGwdvz3vt0",
        "outputId": "e71c83a3-71e1-4fa3-8919-452abfe5f916"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "Traceback (most recent call last):\n",
            "  File \"object_detection/builders/model_builder_test.py\", line 20, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/content/models/research/object_detection/builders/model_builder.py\", line 37, in <module>\n",
            "    from object_detection.meta_architectures import deepmac_meta_arch\n",
            "  File \"/content/models/research/object_detection/meta_architectures/deepmac_meta_arch.py\", line 20, in <module>\n",
            "    from object_detection.models.keras_models import resnet_v1\n",
            "  File \"/content/models/research/object_detection/models/keras_models/resnet_v1.py\", line 21, in <module>\n",
            "    from keras.applications import resnet\n",
            "ImportError: cannot import name 'resnet' from 'keras.applications' (/usr/local/lib/python3.7/dist-packages/keras/applications/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If you forked the repo, you can replace the link.\n",
        "repo_url = 'https://github.com/roboflow-ai/tensorflow-object-detection-faster-rcnn'\n",
        "\n",
        "# Number of training steps - 1000 will train very quickly, but more steps will increase accuracy.\n",
        "num_steps = 5000  # 200000 to improve\n",
        "\n",
        "# Number of evaluation steps.\n",
        "num_eval_steps = 50\n",
        "\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "        'batch_size': 12\n",
        "        #512\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "        'batch_size': 12\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "        'batch_size': 8\n",
        "    },    \n",
        "}\n",
        "\n",
        "# Pick the model you want to use\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "selected_model = 'ssd_mobilenet_v2'\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "# Training batch size fits in Colabe's Tesla K80 GPU memory for selected model.\n",
        "batch_size = MODELS_CONFIG[selected_model]['batch_size']"
      ],
      "metadata": {
        "id": "cRr_lbNVzMwz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "%cd /content\n",
        "\n",
        "repo_dir_path = os.path.abspath(os.path.join('.', os.path.basename(repo_url)))\n",
        "\n",
        "!git clone {repo_url}\n",
        "%cd {repo_dir_path}\n",
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I6oxyyFzObj",
        "outputId": "1d1a20f7-a706-4e8f-950e-ed41804bcd29"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'tensorflow-object-detection-faster-rcnn'...\n",
            "remote: Enumerating objects: 885, done.\u001b[K\n",
            "remote: Total 885 (delta 0), reused 0 (delta 0), pack-reused 885\u001b[K\n",
            "Receiving objects: 100% (885/885), 24.83 MiB | 17.72 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n",
            "/content/tensorflow-object-detection-faster-rcnn\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/tensorflow-object-detection-faster-rcnn/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hk3NpoZzPn3",
        "outputId": "b6290d2c-929a-4f85-a752-9be257dad7e3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/tensorflow-object-detection-faster-rcnn/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ds/VDqChyGc4Z?key=0bdhUaxPfu\n",
        "CcmxPu6AIM?key=k58NBB1xry"
      ],
      "metadata": {
        "id": "mrMebDx415TL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://universe.roboflow.com/ds/2Y8EjuTHe7?key=CBakYJf4p2\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOacceXWzQ3S",
        "outputId": "6fe8eac6-6178-429c-f408-3cc2cc5acc67"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   896  100   896    0     0    438      0  0:00:02  0:00:02 --:--:--   438\n",
            "100 24.8M  100 24.8M    0     0  4810k      0  0:00:05  0:00:05 --:--:-- 11.3M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/Gender.tfrecord    \n",
            " extracting: test/Gender_label_map.pbtxt  \n",
            "   creating: train/\n",
            " extracting: train/Gender.tfrecord   \n",
            " extracting: train/Gender_label_map.pbtxt  \n",
            "   creating: valid/\n",
            " extracting: valid/Gender.tfrecord   \n",
            " extracting: valid/Gender_label_map.pbtxt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training set\n",
        "%ls train\n",
        "# test set\n",
        "%ls test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZjKWe_NzSbS",
        "outputId": "69bb3edc-a04d-4261-8722-1a4f4cd6a47e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gender_label_map.pbtxt  Gender.tfrecord\n",
            "Gender_label_map.pbtxt  Gender.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Update these TFRecord names from \"cells\" and \"cells_label_map\" to your files!\n",
        "test_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/test/Gender.tfrecord'\n",
        "train_record_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/Gender.tfrecord'\n",
        "label_map_pbtxt_fname = '/content/tensorflow-object-detection-faster-rcnn/data/train/Gender_label_map.pbtxt'"
      ],
      "metadata": {
        "id": "jZzCGAfczTdK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib.request\n",
        "import tarfile\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = '/content/models/research/pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "    shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy3Kq0fDzVBs",
        "outputId": "d5f0a790-1b2c-4843-9690-92dbc8b197bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo {DEST_DIR}\n",
        "!ls -alh {DEST_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcInYKsezU7_",
        "outputId": "2fe5bbe6-2939-43d8-d860-a1e0cba6dbd5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 23 root   root  4.0K Dec 19 08:28 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n",
        "fine_tune_checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F4VlU-_SzXo4",
        "outputId": "943d33db-debe-4e91-9b15-13a703be7dcd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/models/research/pretrained_model/model.ckpt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "pipeline_fname = os.path.join('/content/models/research/object_detection/samples/configs/', pipeline_file)\n",
        "\n",
        "assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"
      ],
      "metadata": {
        "id": "dPmva-tqzZcw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=2, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())"
      ],
      "metadata": {
        "id": "yrhjje2_za2D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open(pipeline_fname, 'w') as f:\n",
        "    \n",
        "    # fine_tune_checkpoint\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "    \n",
        "    # tfrecord files train and test.\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
        "\n",
        "    # label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set training batch_size.\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "    \n",
        "    # Set number of classes num_classes.\n",
        "    s = re.sub('num_classes: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "    f.write(s)"
      ],
      "metadata": {
        "id": "8vyz0OIGzct4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat {pipeline_fname}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bna0XRcTzezN",
        "outputId": "0c155620-7744-49e8-e26a-a4d15fd71d24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 2\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 12\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"/content/models/research/pretrained_model/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 5000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Gender.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Gender_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"/content/tensorflow-object-detection-faster-rcnn/data/test/Gender.tfrecord\"\n",
            "  }\n",
            "  label_map_path: \"/content/tensorflow-object-detection-faster-rcnn/data/train/Gender_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'training/'\n",
        "# Optionally remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "3FPZRhZSzfX6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "uZ8FXOhdY4JC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_eval_steps={num_eval_steps}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7Vv77iSzhn7",
        "outputId": "cfe60fe9-9d49-43bd-f672-b9a47e44e24f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W1219 08:35:54.338252 139847988705152 model_lib.py:839] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I1219 08:35:54.338456 139847988705152 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1219 08:35:54.338554 139847988705152 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I1219 08:35:54.338634 139847988705152 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I1219 08:35:54.338723 139847988705152 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W1219 08:35:54.338876 139847988705152 model_lib.py:855] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I1219 08:35:54.338970 139847988705152 model_lib.py:892] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f306907ad90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I1219 08:35:54.339434 139847988705152 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f306907ad90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f30691e34d0>) includes params argument, but params are not passed to Estimator.\n",
            "W1219 08:35:54.339739 139847988705152 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f30691e34d0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I1219 08:35:54.340237 139847988705152 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I1219 08:35:54.340465 139847988705152 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I1219 08:35:54.340690 139847988705152 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W1219 08:35:54.346197 139847988705152 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/Gender.tfrecord']\n",
            "I1219 08:35:54.371986 139847988705152 dataset_builder.py:162] Reading unweighted datasets: ['/content/tensorflow-object-detection-faster-rcnn/data/train/Gender.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/Gender.tfrecord']\n",
            "I1219 08:35:54.372516 139847988705152 dataset_builder.py:79] Reading record datasets for input file: ['/content/tensorflow-object-detection-faster-rcnn/data/train/Gender.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1219 08:35:54.372626 139847988705152 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1219 08:35:54.372712 139847988705152 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W1219 08:35:54.379007 139847988705152 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1219 08:35:54.400979 139847988705152 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W1219 08:36:06.034438 139847988705152 deprecation.py:323] From /content/models/research/object_detection/inputs.py:113: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1219 08:36:06.177947 139847988705152 deprecation.py:323] From /content/models/research/object_detection/inputs.py:97: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1219 08:36:12.204204 139847988705152 api.py:332] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:1004: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1219 08:36:16.029080 139847988705152 deprecation.py:323] From /content/models/research/object_detection/inputs.py:288: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I1219 08:36:19.850667 139847988705152 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W1219 08:36:20.087782 139847988705152 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1219 08:36:23.290107 139847988705152 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1219 08:36:23.329121 139847988705152 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1219 08:36:23.365817 139847988705152 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1219 08:36:23.402338 139847988705152 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1219 08:36:23.438879 139847988705152 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1219 08:36:23.476564 139847988705152 convolutional_box_predictor.py:155] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W1219 08:36:28.477065 139847988705152 deprecation.py:506] From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I1219 08:36:36.098416 139847988705152 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I1219 08:36:36.099870 139847988705152 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I1219 08:37:04.409417 139847988705152 monitored_session.py:240] Graph was finalized.\n",
            "2022-12-19 08:37:04.409829: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
            "2022-12-19 08:37:04.413841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-12-19 08:37:04.414041: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2298680 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-12-19 08:37:04.414086: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-12-19 08:37:04.415759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-12-19 08:37:05.226340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-19 08:37:05.227100: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2297f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-12-19 08:37:05.227136: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2022-12-19 08:37:05.227956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-19 08:37:05.228518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-12-19 08:37:05.228771: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.228934: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.229055: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.229184: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.229318: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.229438: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.229558: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.7/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2022-12-19 08:37:05.229576: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-12-19 08:37:05.229604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-12-19 08:37:05.229620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2022-12-19 08:37:05.229633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I1219 08:37:08.564130 139847988705152 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I1219 08:37:08.853996 139847988705152 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I1219 08:37:50.203804 139847988705152 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "INFO:tensorflow:loss = 17.411722, step = 1\n",
            "I1219 08:38:23.385516 139847988705152 basic_session_run_hooks.py:262] loss = 17.411722, step = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls {model_dir}"
      ],
      "metadata": {
        "id": "iws7C41gzjXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export model"
      ],
      "metadata": {
        "id": "mPxo45LxjGbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "output_directory = './fine_tuned_model'\n",
        "tflite_directory = './fine_tuned_model/tflite'\n",
        "\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path} \n",
        "    \n",
        "\n",
        "!python /content/models/research/object_detection/export_tflite_ssd_graph.py \\\n",
        "    --pipeline_config_path={pipeline_fname} \\\n",
        "    --output_directory={tflite_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path} \\\n",
        "    --add_postprocessing_op=False"
      ],
      "metadata": {
        "id": "1xIDpDu1zk2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tflite_convert \\\n",
        "  --input_shape=1,192,192,3 \\\n",
        "  --input_arrays=normalized_input_image_tensor \\\n",
        "  --output_arrays=raw_outputs/box_encodings,raw_outputs/class_predictions \\\n",
        "  --output_format=TFLITE \\\n",
        "  --inference_type=FLOAT \\\n",
        "  --quantized_input_stats=true \\\n",
        "  --graph_def_file=/content/models/research/fine_tuned_model/tflite/tflite_graph.pb \\\n",
        "  --output_file=\"/content/models/research/fine_tuned_model/gender_quant192x192V2.tflite\""
      ],
      "metadata": {
        "id": "cvU0dDYwzmn-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}